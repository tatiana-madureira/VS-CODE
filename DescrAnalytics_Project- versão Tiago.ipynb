{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(r\"C:\\Users\\pmoreira\\Desktop\\PBS\\DescriptiveAnalysis\\Product_info.csv\")\n",
    "sales = pd.read_csv(r\"C:\\Users\\pmoreira\\Desktop\\PBS\\DescriptiveAnalysis\\Sales_info.csv\")\n",
    "account = pd.read_csv(r\"C:\\Users\\pmoreira\\Desktop\\PBS\\DescriptiveAnalysis\\Account_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(products))\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986193ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(account))\n",
    "account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sales))\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encrypted SKU & Product Name\n",
    "sales_merged = sales.merge(products [['encrypt_sku','product_dsc', 'cat_dsc_ext']], on='encrypt_sku', how='left')\n",
    "sales_merged.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the frequency of each product on the sales data\n",
    "products_frequency = sales_merged[['encrypt_sku','product_dsc']].value_counts()\n",
    "products_frequency\n",
    "\n",
    "#Top 5 products sold\n",
    "top_5_products = products_frequency.head(5)\n",
    "top_5_products.plot (kind ='bar')\n",
    "plt.title('Top 5 Products Sold')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.xlabel('Products')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caracterization of the Transactions\n",
    "transaction_sizes = sales_merged.groupby('transaction_id')['product_dsc'].count()\n",
    "transaction_sizes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea088aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantas transações únicas existem\n",
    "num_transactions = sales_merged['transaction_id'].nunique()\n",
    "\n",
    "# Para cada produto, contar em quantas transações ele aparece\n",
    "product_transaction_counts = sales_merged.groupby('product_dsc')['transaction_id'].nunique()\n",
    "\n",
    "# Calcular o suporte: frequência relativa de transações\n",
    "product_support = product_transaction_counts / num_transactions\n",
    "\n",
    "# Filtrar produtos com suporte >= 0.02\n",
    "\n",
    "products_with_support = product_support[product_support >= 0.02]\n",
    "\n",
    "print(f\"Número de produtos com suporte >= 0.03: {len(products_with_support)}\")\n",
    "products_with_support.sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the Transactions\n",
    "transactions = sales_merged.groupby('transaction_id')['product_dsc'].apply(list).tolist()\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "transactions_matrix = te.fit_transform(transactions)\n",
    "encoded_sales = pd.DataFrame(transactions_matrix, columns=te.columns_)\n",
    "encoded_sales.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Apriori to Get Frequent Co-Purchased Products (0,2% of the transactions)\n",
    "min_supp = 0.002\n",
    "freq_copurchased = apriori(encoded_sales, min_support=min_supp, use_colnames=True) \n",
    "print(f\"Number of Frequent Co-Purchased Products: {len(freq_copurchased)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff186498",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_copurchased.sort_values(by= \"support\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_copurchased['length'] = freq_copurchased['itemsets'].apply(len)\n",
    "print(freq_copurchased['length'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b04717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate association rules from frequent itemsets\n",
    "min_conf=0.1\n",
    "rules = association_rules(freq_copurchased, metric=\"confidence\", min_threshold=min_conf,num_itemsets=0.2)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run Apriori with lower support\n",
    "min_supp = 0.002  # 0.2%\n",
    "freq_copurchased = apriori(encoded_sales, min_support=min_supp, use_colnames=True)\n",
    "\n",
    "# Add length of itemset\n",
    "freq_copurchased['length'] = freq_copurchased['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# Filter itemsets with more than 1 item (i.e., combinations)\n",
    "filtered = freq_copurchased[freq_copurchased['length'] > 1]\n",
    "\n",
    "# Check if there are any\n",
    "print(f\"Número de combinações com suporte >= {min_supp}: {len(filtered)}\")\n",
    "\n",
    "if not filtered.empty:\n",
    "    # Get top 10 by support\n",
    "    top10 = filtered.sort_values(by='support', ascending=False).head(10)\n",
    "    \n",
    "    # Convert sets to strings for labeling\n",
    "    top10['itemset_str'] = top10['itemsets'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(top10['itemset_str'], top10['support'])\n",
    "    plt.title(\"Top 10 Frequent Itemsets (size > 1)\")\n",
    "    plt.xlabel(\"Itemset\")\n",
    "    plt.ylabel(\"Support\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Ainda não há itemsets de tamanho > 1 com esse suporte mínimo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Gerar regras\n",
    "rules = association_rules(freq_copurchased, metric=\"confidence\", min_threshold=0.2)\n",
    "\n",
    "# Adicionar coluna com o número de itens no antecedente\n",
    "rules['antecedent_len'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "\n",
    "# Filtrar regras com pelo menos 1 item no antecedente e suporte mínimo\n",
    "rules_filtered = rules[(rules['antecedent_len'] >= 1) & (rules['support'] >= 0.002)]\n",
    "\n",
    "# Ordenar por lift e mostrar as top 10\n",
    "top10_rules = rules_filtered.sort_values(by='confidence', ascending=False).head(10)\n",
    "\n",
    "# Mostrar colunas relevantes\n",
    "top10_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que você tenha um DataFrame com as transações (ex: trans_id, cat_dsc_ext)\n",
    "# Agrupar categorias por transação\n",
    "basket = sales_merged.groupby(['transaction_id', 'cat_dsc_ext']).size().unstack().fillna(0)\n",
    "\n",
    "# Converter para 1/0 (presença/ausência do item)\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d376fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Gerar itemsets frequentes com suporte mínimo\n",
    "freq_items = apriori(basket, min_support=0.002, use_colnames=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6508cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar tamanho do antecedente\n",
    "rules['antecedent_len'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "\n",
    "# Filtrar regras com pelo menos 1 item no antecedente e suporte mínimo\n",
    "rules_filtered = rules[(rules['antecedent_len'] >= 1) & (rules['support'] >= 0.002)]\n",
    "\n",
    "# Ordenar pelas 10 regras com maior confiança\n",
    "top10_rules = rules_filtered.sort_values(by='confidence', ascending=False).head(10)\n",
    "\n",
    "# Mostrar como tabela limpa (sem índice)\n",
    "print(\"\\n=== ASSOCIATION RULES GENERATION ===\")\n",
    "print(f\"Generated {len(rules_filtered)} association rules\\n\")\n",
    "print(\"Top 10 rules by confidence:\\n\")\n",
    "print(top10_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd730d13",
   "metadata": {},
   "source": [
    "Let´s segment the customer for the strongest itemsets (there 2 only two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Merge ALL product and account columns into sales\n",
    "# ----------------------------\n",
    "sales_merged_account = sales_merged.merge(account, on='account_no', how='left')  # All account columns\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Build transactions from ALL account characteristics per transaction\n",
    "# ----------------------------\n",
    "\n",
    "# Drop columns not useful for profiling (like IDs, dates, numbers)\n",
    "account_cols = account.select_dtypes(include='object').columns.tolist()\n",
    "account_cols = [col for col in account_cols if col != 'account_no']  # Remove ID column\n",
    "\n",
    "# Fill NAs to avoid issues\n",
    "sales_merged_account[account_cols] = sales_merged_account[account_cols].fillna('Missing')\n",
    "\n",
    "# Aggregate account features by transaction\n",
    "account_features = sales_merged_account.groupby('transaction_id')[account_cols].agg(lambda x: list(set(x)))\n",
    "\n",
    "# Convert each transaction into a flat list of attribute values\n",
    "transactions = account_features.apply(lambda row: sum(row.tolist(), []), axis=1).tolist()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Define WRAcc target: 1 if flour + sugar are both bought\n",
    "# ----------------------------\n",
    "product_groups = sales_merged_account.groupby('transaction_id')['product_dsc'].apply(list)\n",
    "'''\n",
    "transaction_targets = product_groups.apply(lambda items: int(\n",
    "    'FAR TRIGO C/FER SUP FINA CONTINENTE 1KG' in items and\n",
    "    'AÇÚCAR BRANCO CONTINENTE 1KG' in items)).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Encode account characteristics using TransactionEncoder\n",
    "# ----------------------------\n",
    "te = TransactionEncoder()\n",
    "transactions_matrix = te.fit_transform(transactions)\n",
    "encoded_sales = pd.DataFrame(transactions_matrix, columns=te.columns_)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Run Apriori (min support ≥ 0.2%)\n",
    "# ----------------------------\n",
    "min_support = 0.002\n",
    "frequent_itemsets = apriori(encoded_sales, min_support=min_support, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Compute WRAcc\n",
    "# ----------------------------\n",
    "def compute_wracc(itemset, df, y):\n",
    "    if not itemset:\n",
    "        return 0\n",
    "    cover = df[list(itemset)].all(axis=1)\n",
    "    if cover.sum() == 0:\n",
    "        return 0\n",
    "    p_s = y[cover].mean()\n",
    "    p_d = y.mean()\n",
    "    return cover.mean() * (p_s - p_d)\n",
    "\n",
    "frequent_itemsets['WRAcc'] = frequent_itemsets['itemsets'].apply(\n",
    "    lambda s: compute_wracc(s, encoded_sales, transaction_targets)\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top itemsets by WRAcc\n",
    "# ----------------------------\n",
    "filtered = frequent_itemsets[frequent_itemsets['length'] >= 1]\n",
    "print(f\"\\nNúmero de combinações com suporte >= {min_support}: {len(filtered)}\")\n",
    "\n",
    "if not filtered.empty:\n",
    "    top10 = filtered.sort_values(by='WRAcc', ascending=False).head(20)\n",
    "    print(\"\\nTop 10 Account Characteristic Combinations by WRAcc (length >= 1):\\n\")\n",
    "    print(top10[['itemsets', 'support', 'WRAcc']].to_string(index=False))\n",
    "else:\n",
    "    print(\"Ainda não há combinações de características de conta com esse suporte mínimo.\")\n",
    "'''\n",
    "# ----------------------------Agora testar para outro conjunto de dados----------------------------\n",
    "\n",
    "transaction_targets = product_groups.apply(lambda items: int(\n",
    "    'PERNA DE FRANGO (2KG) COMPRA/AT' in items and\n",
    "    'PEITO DE FRANGO (2KG) COMPRA/AT' in items)).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Encode account characteristics using TransactionEncoder\n",
    "# ----------------------------\n",
    "te = TransactionEncoder()\n",
    "transactions_matrix = te.fit_transform(transactions)\n",
    "encoded_sales = pd.DataFrame(transactions_matrix, columns=te.columns_)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Run Apriori (min support ≥ 0.2%)\n",
    "# ----------------------------\n",
    "min_support = 0.002\n",
    "frequent_itemsets = apriori(encoded_sales, min_support=min_support, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Compute WRAcc\n",
    "# ----------------------------\n",
    "def compute_wracc(itemset, df, y):\n",
    "    if not itemset:\n",
    "        return 0\n",
    "    cover = df[list(itemset)].all(axis=1)\n",
    "    if cover.sum() == 0:\n",
    "        return 0\n",
    "    p_s = y[cover].mean()\n",
    "    p_d = y.mean()\n",
    "    return cover.mean() * (p_s - p_d)\n",
    "\n",
    "frequent_itemsets['WRAcc'] = frequent_itemsets['itemsets'].apply(\n",
    "    lambda s: compute_wracc(s, encoded_sales, transaction_targets)\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top itemsets by WRAcc\n",
    "# ----------------------------\n",
    "filtered = frequent_itemsets[frequent_itemsets['length'] >= 1]\n",
    "print(f\"\\nNúmero de combinações com suporte >= {min_support}: {len(filtered)}\")\n",
    "\n",
    "if not filtered.empty:\n",
    "    top10 = filtered.sort_values(by='WRAcc', ascending=False).head(20)\n",
    "    print(\"\\nTop 10 Account Characteristic Combinations by WRAcc (length >= 1):\\n\")\n",
    "    print(top10[['itemsets', 'support', 'WRAcc']].to_string(index=False))\n",
    "else:\n",
    "    print(\"Ainda não há combinações de características de conta com esse suporte mínimo.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
